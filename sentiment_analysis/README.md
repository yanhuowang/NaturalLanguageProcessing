# natualLanguageProcessing
This project focuses on how machine learning based MaxEnt classifier works in sentiment analysis. I investigated different feature sets for training (including using unigram features only, using bigram features only, using both unigram and bigram features, adding position information and adding parts of speed tagging) in order to obtain the best results in the classification. Information gain calculation was used to prevent from overfitting and the curse of dimensionality. Negations (e.g. not, isn’t) were handled by a preprocessing technique to improve the classification performance. The results were evaluated by accuracy, precision, recall and F-measure. The best result was obtained when using 2000 most frequent adjectives, adverbs and verbs as feature set with information gain calculation and negation preprocessing. The average accuracy for three runs is 0.880, compared with 0.798 obtain from Naïve Bayes baseline method, indicating that MaxEnt outperforms Naïve Bayes at sentiment analysis tasks.
